{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection\n",
    "Get a shitton of scientific papers in various categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxivscraper\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['cs', 'econ', 'eess', 'math', 'physics', 'q-bio', 'q-fin', 'stat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping category: cs...\n",
      "fetching up to  1000 records...\n",
      "fetching up to  2000 records...\n",
      "fetching up to  3000 records...\n",
      "fetching up to  4000 records...\n",
      "fetching up to  5000 records...\n",
      "fetching up to  6000 records...\n",
      "fetching up to  7000 records...\n",
      "fetching up to  8000 records...\n",
      "fetching up to  9000 records...\n",
      "fetching up to  10000 records...\n",
      "fetching up to  11000 records...\n",
      "fetching up to  12000 records...\n",
      "fetching up to  13000 records...\n",
      "fetching up to  14000 records...\n",
      "fetching up to  15000 records...\n",
      "fetching up to  16000 records...\n",
      "fetching up to  17000 records...\n",
      "fetching up to  18000 records...\n",
      "fetching up to  19000 records...\n",
      "fetching up to  20000 records...\n",
      "fetching up to  21000 records...\n",
      "fetching up to  22000 records...\n",
      "fetching is completed in 362.6 seconds.\n",
      "Total number of records 22000\n",
      "Scraping category: econ...\n",
      "fetching up to  1000 records...\n",
      "fetching up to  2000 records...\n",
      "fetching up to  3000 records...\n",
      "fetching is completed in 144.4 seconds.\n",
      "Total number of records 2636\n",
      "Scraping category: eess...\n",
      "fetching up to  1000 records...\n",
      "Got 503. Retrying after 30 seconds.\n",
      "fetching up to  1000 records...\n",
      "fetching up to  2000 records...\n",
      "fetching up to  3000 records...\n",
      "fetching up to  4000 records...\n",
      "fetching up to  5000 records...\n",
      "fetching up to  6000 records...\n",
      "fetching up to  7000 records...\n",
      "fetching up to  8000 records...\n",
      "fetching up to  9000 records...\n",
      "fetching up to  10000 records...\n",
      "fetching up to  11000 records...\n",
      "fetching up to  12000 records...\n",
      "fetching up to  13000 records...\n",
      "fetching up to  14000 records...\n",
      "fetching up to  15000 records...\n",
      "fetching up to  16000 records...\n",
      "fetching is completed in 320.4 seconds.\n",
      "Total number of records 16000\n",
      "Scraping category: math...\n",
      "fetching up to  1000 records...\n",
      "fetching up to  2000 records...\n",
      "fetching up to  3000 records...\n",
      "fetching up to  4000 records...\n",
      "Got 503. Retrying after 30 seconds.\n",
      "fetching up to  4000 records...\n",
      "fetching up to  5000 records...\n",
      "fetching up to  6000 records...\n",
      "fetching up to  7000 records...\n",
      "fetching up to  8000 records...\n",
      "fetching up to  9000 records...\n",
      "fetching up to  10000 records...\n",
      "fetching up to  11000 records...\n",
      "fetching up to  12000 records...\n",
      "fetching up to  13000 records...\n",
      "fetching is completed in 303.6 seconds.\n",
      "Total number of records 13000\n",
      "Scraping category: physics...\n",
      "fetching up to  1000 records...\n",
      "fetching up to  2000 records...\n",
      "fetching up to  3000 records...\n",
      "fetching up to  4000 records...\n",
      "fetching up to  5000 records...\n",
      "fetching up to  6000 records...\n",
      "fetching up to  7000 records...\n",
      "fetching up to  8000 records...\n",
      "fetching up to  9000 records...\n",
      "fetching up to  10000 records...\n",
      "fetching up to  11000 records...\n",
      "fetching up to  12000 records...\n",
      "fetching up to  13000 records...\n",
      "fetching up to  14000 records...\n",
      "fetching up to  15000 records...\n",
      "fetching up to  16000 records...\n",
      "fetching up to  17000 records...\n",
      "fetching up to  18000 records...\n",
      "fetching up to  19000 records...\n",
      "fetching up to  20000 records...\n",
      "fetching is completed in 311.3 seconds.\n",
      "Total number of records 20000\n",
      "Scraping category: q-bio...\n",
      "fetching up to  1000 records...\n",
      "fetching up to  2000 records...\n",
      "fetching up to  3000 records...\n",
      "fetching up to  4000 records...\n",
      "fetching up to  5000 records...\n",
      "fetching is completed in 73.4 seconds.\n",
      "Total number of records 4782\n",
      "Scraping category: q-fin...\n",
      "fetching up to  1000 records...\n",
      "fetching up to  2000 records...\n",
      "fetching up to  3000 records...\n",
      "fetching is completed in 33.6 seconds.\n",
      "Total number of records 2830\n",
      "Scraping category: stat...\n",
      "fetching up to  1000 records...\n",
      "Got 503. Retrying after 30 seconds.\n",
      "fetching up to  1000 records...\n",
      "fetching up to  2000 records...\n",
      "fetching up to  3000 records...\n",
      "fetching up to  4000 records...\n",
      "fetching up to  5000 records...\n",
      "fetching up to  6000 records...\n",
      "fetching up to  7000 records...\n",
      "fetching up to  8000 records...\n",
      "fetching up to  9000 records...\n",
      "fetching up to  10000 records...\n",
      "fetching up to  11000 records...\n",
      "fetching up to  12000 records...\n",
      "fetching up to  13000 records...\n",
      "fetching up to  14000 records...\n",
      "fetching up to  15000 records...\n",
      "fetching up to  16000 records...\n",
      "fetching up to  17000 records...\n",
      "fetching up to  18000 records...\n",
      "fetching up to  19000 records...\n",
      "fetching is completed in 283.2 seconds.\n",
      "Total number of records 18177\n"
     ]
    }
   ],
   "source": [
    "papers = []\n",
    "seen_ids = set()\n",
    "for category in categories:\n",
    "    print(f'Scraping category: {category}...')\n",
    "    scraper = arxivscraper.Scraper(category=category, date_from='2021-01-01')\n",
    "    for paper in scraper.scrape():\n",
    "        if paper['id'] in seen_ids:\n",
    "            continue\n",
    "        papers.append(paper)\n",
    "        seen_ids.add(paper['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ('id', 'title', 'categories', 'abstract', 'doi', 'created', 'updated', 'authors')\n",
    "df = pd.DataFrame(papers, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('data/arxiv_papers.json', orient='records', indent=2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9a909dbf399a34d8e6d170b6c066d56ff1811b263bbac8a7706d7115577aaf2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
